# Assignment 1: Forced Alignment using Montreal Forced Aligner (MFA)

## ğŸ“‹ Project Overview

This project implements a complete forced alignment pipeline using the Montreal Forced Aligner (MFA) to automatically match audio recordings with their corresponding text transcriptions at the word and phoneme level.

**Repository**: https://github.com/saksham-1304/IIIT-H-Assignment  
**Date**: November 7, 2025

## ğŸ¯ Objective

Set up and execute a complete forced alignment pipeline to understand how automatic alignment works between speech audio and phonetic transcription.

## ğŸ“ Dataset Description

The dataset contains 6 audio files with corresponding transcripts:

### 1. Broadcast News Dataset (F2BJRLP series)
- **Files**: `F2BJRLP1`, `F2BJRLP2`, `F2BJRLP3`
- **Content**: Continuous speech, news broadcasts, formal narratives
- **Transcript format**: Multi-line paragraphs with natural punctuation
- **Duration**: Longer segments (typically several minutes)

### 2. ISLE Speech Dataset (ISLE_SESS series)
- **Files**: `ISLE_SESS0131_BLOCKD02_01_sprt1`, `ISLE_SESS0131_BLOCKD02_02_sprt1`, `ISLE_SESS0131_BLOCKD02_03_sprt1`
- **Content**: Minimal pair utterances (single short phrases)
- **Transcript format**: Single line, uppercase (e.g., "I SAID WHITE NOT BAIT")
- **Duration**: Short utterances (~1-3 seconds)

## ğŸ› ï¸ Installation Instructions

### Step 1: Install Miniconda (Required)

1. Download Miniconda for Windows:
   - Visit: https://docs.conda.io/en/latest/miniconda.html
   - Download: **Miniconda3 Windows 64-bit** installer
   - Direct link: https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe

2. Run the installer:
   - âœ… **Important**: Check "Add Miniconda3 to my PATH environment variable"
   - Complete the installation
   - Restart PowerShell/Command Prompt

3. Verify installation:
   ```powershell
   conda --version
   ```
   Expected output: `conda 23.x.x` or similar

### Step 2: Install Montreal Forced Aligner

```powershell
# Update conda
conda update -n base -c defaults conda

# Install MFA
conda install -c conda-forge montreal-forced-aligner

# Verify MFA installation
mfa version
```

Expected output: `Montreal Forced Aligner version 2.x.x`

### Step 3: Download Pre-trained Models

```powershell
# Download English US pronunciation dictionary (ARPA format)
mfa model download dictionary english_us_arpa

# Download English US acoustic model
mfa model download acoustic english_us_arpa

# Verify downloaded models
mfa model list
```

You should see both `english_us_arpa` listed under dictionaries and acoustic models.

## ğŸ“Š Dataset Preparation

### Step 1: Validate Dataset

Run the validation script to ensure all audio files have corresponding transcripts:

```powershell
python validate_dataset.py
```

Expected output:
```
============================================================
MFA Dataset Validation
============================================================

âœ“ Found 6 audio files in 'wav/'

Paired Files (6):
  âœ“ F2BJRLP1.wav â†’ F2BJRLP1.TXT (203 chars)
  âœ“ F2BJRLP2.wav â†’ F2BJRLP2.TXT (285 chars)
  âœ“ F2BJRLP3.wav â†’ F2BJRLP3.TXT (312 chars)
  âœ“ ISLE_SESS0131_BLOCKD02_01_sprt1.wav â†’ ISLE_SESS0131_BLOCKD02_01_sprt1.txt (23 chars)
  âœ“ ISLE_SESS0131_BLOCKD02_02_sprt1.wav â†’ ISLE_SESS0131_BLOCKD02_02_sprt1.txt (23 chars)
  âœ“ ISLE_SESS0131_BLOCKD02_03_sprt1.wav â†’ ISLE_SESS0131_BLOCKD02_03_sprt1.txt (23 chars)

âœ… All audio files have matching transcripts!
```

### Step 2: Prepare MFA Dataset

Convert transcripts to MFA-compatible format (`.lab` files):

```powershell
python prepare_mfa_dataset.py
```

This script:
- Creates `mfa_data/` directory
- Copies audio files
- Converts transcripts to `.lab` format (single-line text)
- Handles multi-line F2BJRLP transcripts by joining them
- Preserves single-line ISLE transcripts

**Output structure**:
```
mfa_data/
  F2BJRLP1.wav
  F2BJRLP1.lab
  F2BJRLP2.wav
  F2BJRLP2.lab
  ...
```

## ğŸš€ Running Forced Alignment

### Execute MFA Alignment

```powershell
# Navigate to project directory (if not already there)
cd "C:\Users\HP\Downloads\Assignment\Assignment\IIIT-H-Assignment"

# Run forced alignment
mfa align mfa_data/ english_us_arpa english_us_arpa output_textgrids/
```

**Parameters**:
- `mfa_data/` - Input directory with audio and transcript files
- `english_us_arpa` - Pronunciation dictionary
- `english_us_arpa` - Acoustic model
- `output_textgrids/` - Output directory for TextGrid files

### Expected Output

The alignment process will:
1. Validate input files
2. Generate pronunciation variants
3. Perform acoustic alignment
4. Create TextGrid files in `output_textgrids/` directory

**Output files**:
```
output_textgrids/
  F2BJRLP1.TextGrid
  F2BJRLP2.TextGrid
  F2BJRLP3.TextGrid
  ISLE_SESS0131_BLOCKD02_01_sprt1.TextGrid
  ISLE_SESS0131_BLOCKD02_02_sprt1.TextGrid
  ISLE_SESS0131_BLOCKD02_03_sprt1.TextGrid
```

## ğŸ” Inspecting Results

### Using Praat (Recommended)

1. **Download and Install Praat**:
   - Visit: https://www.fon.hum.uva.nl/praat/
   - Download the Windows version
   - Install and launch Praat

2. **Open TextGrid with Audio**:
   - In Praat: `Open` â†’ `Read from file`
   - Select a `.wav` file from `wav/` directory
   - Select the corresponding `.TextGrid` file from `output_textgrids/`
   - Select both objects â†’ `View & Edit`

3. **Analyze Alignment**:
   - **Words tier**: Shows start/end times for each word
   - **Phones tier**: Shows start/end times for each phoneme
   - Click on segments to play individual words/phonemes
   - Zoom in to examine phoneme boundaries

### Using Python Script

I've included an analysis script to programmatically inspect TextGrids:

```powershell
python analyze_textgrids.py
```

This script extracts and displays:
- Word boundaries and durations
- Phoneme boundaries and durations
- Alignment statistics

## ğŸ“ Example Alignment Output

For the utterance: **"HELLO WORLD"**

**Word tier**:
```
0.00 â€“ 0.45   HELLO
0.45 â€“ 0.90   WORLD
```

**Phone tier**:
```
0.00 â€“ 0.10   HH
0.10 â€“ 0.25   AH
0.25 â€“ 0.40   L
0.40 â€“ 0.45   OW
0.45 â€“ 0.55   W
0.55 â€“ 0.70   ER
0.70 â€“ 0.85   L
0.85 â€“ 0.90   D
```

## ğŸ“Š Key Observations

### 1. Alignment Quality
- **F2BJRLP files**: Continuous speech with natural pauses, generally good alignment
- **ISLE files**: Short utterances with clear articulation, excellent alignment

### 2. Common Alignment Issues
- **Silence handling**: Leading/trailing silence sometimes included in word boundaries
- **Fast speech**: Rapid articulation can cause phoneme boundary merging
- **Background noise**: May affect boundary precision

### 3. Model Performance
- **english_us_arpa dictionary**: Comprehensive coverage of English phonemes
- **english_us_arpa acoustic model**: Trained on diverse speech data, performs well on both formal and conversational speech

## ğŸ“‚ Project Structure

```
IIIT-H-Assignment/
â”‚
context and instructions
â”‚
â”œâ”€â”€ wav/                          # Original audio files (6 files)
â”‚   â”œâ”€â”€ F2BJRLP1.wav
â”‚   â”œâ”€â”€ F2BJRLP2.wav
â”‚   â”œâ”€â”€ F2BJRLP3.wav
â”‚   â”œâ”€â”€ ISLE_SESS0131_BLOCKD02_01_sprt1.wav
â”‚   â”œâ”€â”€ ISLE_SESS0131_BLOCKD02_02_sprt1.wav
â”‚   â””â”€â”€ ISLE_SESS0131_BLOCKD02_03_sprt1.wav
â”‚
â”œâ”€â”€ transcripts/                  # Original transcripts (6 files)
â”‚   â”œâ”€â”€ F2BJRLP1.TXT
â”‚   â”œâ”€â”€ F2BJRLP2.TXT
â”‚   â”œâ”€â”€ F2BJRLP3.TXT
â”‚   â”œâ”€â”€ ISLE_SESS0131_BLOCKD02_01_sprt1.txt
â”‚   â”œâ”€â”€ ISLE_SESS0131_BLOCKD02_02_sprt1.txt
â”‚   â””â”€â”€ ISLE_SESS0131_BLOCKD02_03_sprt1.txt
â”‚
â”œâ”€â”€ mfa_data/                     # MFA-formatted dataset
â”‚   â”œâ”€â”€ [audio].wav + .lab files (6 pairs)
â”‚
â”œâ”€â”€ output_textgrids/             # Generated TextGrid files
â”‚   â”œâ”€â”€ [audio].TextGrid (6 files)
â”‚   â””â”€â”€ alignment_analysis.csv
â”‚
â”œâ”€â”€ validate_dataset.py           # Dataset validation script
â”œâ”€â”€ prepare_mfa_dataset.py        # MFA dataset preparation script
â”œâ”€â”€ analyze_textgrids.py          # TextGrid analysis script
â”œâ”€â”€ run_mfa.py                    # Automated alignment pipeline
â”‚
â”œâ”€â”€ Assignment1.pdf               # Assignment requirements
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ .gitignore                    # Git ignore patterns
```

## ğŸ“ What is Forced Alignment?

Forced alignment is an automated process that:

1. **Takes as input**:
   - Audio recording of speech
   - Text transcript of what was said

2. **Produces as output**:
   - Precise timestamps for when each word starts and ends
   - Precise timestamps for when each phoneme starts and ends

3. **How it works**:
   - Uses a pronunciation dictionary to convert words to phonemes
   - Uses an acoustic model trained on speech data
   - Applies Viterbi algorithm to find optimal alignment
   - Generates TextGrid files with boundary annotations

## ğŸ”§ Automation Script

For convenience, use the automated pipeline script:

```powershell
python run_mfa.py
```

This script runs the entire pipeline:

1. Validates dataset
2. Prepares MFA data
3. Runs forced alignment
4. Analyzes results

## ğŸ“¦ Requirements

- **Python**: 3.8 or higher
- **Conda**: Miniconda or Anaconda
- **MFA**: Montreal Forced Aligner 2.x
- **Praat**: For visualization (optional but recommended)

### Python Dependencies

```
textgrid==1.6.0  # For TextGrid parsing
scipy>=1.9.0     # For audio file handling
```

Install with:
```powershell
pip install textgrid scipy
```

## ğŸ† Extra Credit Opportunities

### 1. Train Custom Dictionary

Use MFA's G2P (Grapheme-to-Phoneme) model to generate a custom dictionary:

```powershell
mfa g2p english_us_arpa mfa_data/ custom_dict.txt
mfa align mfa_data/ custom_dict.txt english_us_arpa output_textgrids_custom/
```

### 2. Compare Multiple Acoustic Models

Try different acoustic models and compare alignment quality:

```powershell
# Download alternative model
mfa model download acoustic english_mfa

# Run alignment with different model
mfa align mfa_data/ english_us_arpa english_mfa output_textgrids_mfa/
```

### 3. Automated Pipeline

The `run_mfa.py` script provides full automation with error handling and logging.

## ğŸ› Troubleshooting

### Issue: "conda command not found"

- **Solution**: Restart PowerShell or add conda to PATH manually
- Check: `C:\Users\[YourUsername]\miniconda3\Scripts` should be in PATH

### Issue: MFA alignment fails

- **Solution**: Check that `.lab` files contain valid text
- Verify models are downloaded: `mfa model list`
- Check audio files are valid WAV format (16-bit PCM recommended)

### Issue: Poor alignment quality

- **Solution**:
  - Check transcript accuracy
  - Ensure audio quality is good
  - Try different acoustic models
  - Consider training custom dictionary

## ğŸ“§ Submission

- **GitHub Repository**: [IIIT-H-Assignment](https://github.com/saksham-1304/IIIT-H-Assignment)
- **Outputs**: All TextGrid files in `output_textgrids/`

Ensure all links are publicly accessible for evaluation.

## ğŸ“š Resources

- [MFA Documentation](https://montreal-forced-aligner.readthedocs.io/)
- [Praat Software](https://www.fon.hum.uva.nl/praat/)
- [TextGrid Format Guide](https://www.fon.hum.uva.nl/praat/manual/TextGrid_file_formats.html)

## ğŸ‘¤ Author

**Saksham**  
GitHub: [saksham-1304](https://github.com/saksham-1304)

## ğŸ“„ License

This project is for educational purposes as part of IIIT Hyderabad coursework.

---

**Last Updated**: November 7, 2025
