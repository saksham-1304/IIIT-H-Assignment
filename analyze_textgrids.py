"""
Analyze TextGrid Files Generated by MFA
Extracts and displays word and phoneme boundaries with statistics.
"""

import os
from pathlib import Path

def parse_textgrid(filepath):
    """
    Parse a Praat TextGrid file manually.
    Returns a dictionary with word and phone tiers.
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    tiers = {}
    current_tier = None
    current_intervals = []
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # Detect tier name
        if 'name = ' in line:
            tier_name = line.split('"')[1] if '"' in line else line.split('=')[1].strip()
            current_tier = tier_name
            current_intervals = []
        
        # Detect interval
        if line.startswith('intervals ['):
            interval = {}
            i += 1
            # Read xmin
            if i < len(lines) and 'xmin' in lines[i]:
                interval['xmin'] = float(lines[i].split('=')[1].strip())
            i += 1
            # Read xmax
            if i < len(lines) and 'xmax' in lines[i]:
                interval['xmax'] = float(lines[i].split('=')[1].strip())
            i += 1
            # Read text
            if i < len(lines) and 'text' in lines[i]:
                text_line = lines[i].strip()
                if '"' in text_line:
                    interval['text'] = text_line.split('"')[1]
                else:
                    interval['text'] = ""
            
            current_intervals.append(interval)
            
            # Save tier when complete
            if current_tier and len(current_intervals) > 0:
                tiers[current_tier] = current_intervals
        
        i += 1
    
    return tiers


def analyze_single_textgrid(textgrid_path):
    """Analyze a single TextGrid file and print results."""
    
    print(f"\n{'='*70}")
    print(f"File: {os.path.basename(textgrid_path)}")
    print(f"{'='*70}")
    
    try:
        tiers = parse_textgrid(textgrid_path)
        
        # Find word and phone tiers (names may vary)
        word_tier = None
        phone_tier = None
        
        for tier_name in tiers.keys():
            if 'word' in tier_name.lower():
                word_tier = tiers[tier_name]
            elif 'phone' in tier_name.lower():
                phone_tier = tiers[tier_name]
        
        # Display words
        if word_tier:
            print("\n--- WORD TIER ---")
            non_empty_words = [w for w in word_tier if w['text'].strip()]
            print(f"Total words: {len(non_empty_words)}")
            print(f"\n{'Start':>8} {'End':>8} {'Duration':>10} {'Word'}")
            print("-" * 50)
            
            for word in non_empty_words[:20]:  # Show first 20 words
                duration = word['xmax'] - word['xmin']
                print(f"{word['xmin']:8.3f} {word['xmax']:8.3f} {duration:10.3f}s   {word['text']}")
            
            if len(non_empty_words) > 20:
                print(f"... ({len(non_empty_words) - 20} more words)")
        
        # Display phones
        if phone_tier:
            print("\n--- PHONE TIER ---")
            non_empty_phones = [p for p in phone_tier if p['text'].strip()]
            print(f"Total phonemes: {len(non_empty_phones)}")
            print(f"\n{'Start':>8} {'End':>8} {'Duration':>10} {'Phone'}")
            print("-" * 50)
            
            for phone in non_empty_phones[:30]:  # Show first 30 phones
                duration = phone['xmax'] - phone['xmin']
                print(f"{phone['xmin']:8.3f} {phone['xmax']:8.3f} {duration:10.3f}s   {phone['text']}")
            
            if len(non_empty_phones) > 30:
                print(f"... ({len(non_empty_phones) - 30} more phonemes)")
            
            # Calculate statistics
            durations = [p['xmax'] - p['xmin'] for p in non_empty_phones]
            if durations:
                avg_duration = sum(durations) / len(durations)
                min_duration = min(durations)
                max_duration = max(durations)
                
                print(f"\n--- STATISTICS ---")
                print(f"Average phoneme duration: {avg_duration:.4f}s")
                print(f"Min phoneme duration: {min_duration:.4f}s")
                print(f"Max phoneme duration: {max_duration:.4f}s")
        
        if not word_tier and not phone_tier:
            print("\n⚠ Could not find word or phone tiers in this TextGrid")
            print(f"Available tiers: {list(tiers.keys())}")
    
    except Exception as e:
        print(f"\n❌ Error analyzing {textgrid_path}: {e}")


def analyze_all_textgrids():
    """Analyze all TextGrid files in the output directory."""
    
    base_dir = Path(__file__).parent
    textgrid_dir = base_dir / "output_textgrids"
    
    if not textgrid_dir.exists():
        print(f"❌ Directory not found: {textgrid_dir}")
        print("\nPlease run MFA alignment first:")
        print("  mfa align mfa_data/ english_us_arpa english_us_arpa output_textgrids/")
        return
    
    textgrid_files = sorted(textgrid_dir.glob("*.TextGrid"))
    
    if not textgrid_files:
        print(f"❌ No TextGrid files found in {textgrid_dir}")
        return
    
    print("="*70)
    print("MFA TEXTGRID ANALYSIS")
    print("="*70)
    print(f"\nFound {len(textgrid_files)} TextGrid files")
    
    for tg_file in textgrid_files:
        analyze_single_textgrid(tg_file)
    
    print(f"\n{'='*70}")
    print("ANALYSIS COMPLETE")
    print(f"{'='*70}")


if __name__ == "__main__":
    analyze_all_textgrids()
