"""
Dataset Validation Script for MFA Forced Alignment
Validates that all audio files have corresponding transcripts and checks file integrity.
"""

import os
from pathlib import Path

def validate_dataset():
    """Validate the audio-transcript pairing for MFA."""
    
    base_dir = Path(__file__).parent
    wav_dir = base_dir / "wav"
    transcript_dir = base_dir / "transcripts"
    
    print("=" * 60)
    print("MFA Dataset Validation")
    print("=" * 60)
    
    # Get all wav files
    wav_files = sorted([f for f in os.listdir(wav_dir) if f.endswith('.wav')])
    
    print(f"\nâœ“ Found {len(wav_files)} audio files in 'wav/'")
    
    # Track validation results
    paired_files = []
    missing_transcripts = []
    
    for wav_file in wav_files:
        basename = os.path.splitext(wav_file)[0]
        
        # Check for both .txt and .TXT extensions (case-sensitive on some systems)
        txt_path_lower = transcript_dir / f"{basename}.txt"
        txt_path_upper = transcript_dir / f"{basename}.TXT"
        
        if txt_path_lower.exists():
            transcript_path = txt_path_lower
            paired = True
        elif txt_path_upper.exists():
            transcript_path = txt_path_upper
            paired = True
        else:
            paired = False
            transcript_path = None
        
        if paired:
            # Read transcript to verify it's not empty
            with open(transcript_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                
            paired_files.append({
                'audio': wav_file,
                'transcript': transcript_path.name,
                'type': 'ISLE' if 'ISLE' in wav_file else 'F2BJRLP',
                'content_preview': content[:50] + '...' if len(content) > 50 else content
            })
        else:
            missing_transcripts.append(wav_file)
    
    # Print results
    print(f"\nâœ“ Successfully paired: {len(paired_files)}/{len(wav_files)} files")
    
    if missing_transcripts:
        print(f"\nâš  Missing transcripts for:")
        for wav in missing_transcripts:
            print(f"  - {wav}")
    
    # Show file type breakdown
    print("\n" + "=" * 60)
    print("Dataset Breakdown:")
    print("=" * 60)
    
    isle_files = [f for f in paired_files if f['type'] == 'ISLE']
    f2bjrlp_files = [f for f in paired_files if f['type'] == 'F2BJRLP']
    
    print(f"\nðŸ“¢ Broadcast News (F2BJRLP): {len(f2bjrlp_files)} files")
    print("   - Longer audio segments")
    print("   - Multi-line narrative transcripts")
    for f in f2bjrlp_files:
        print(f"   â€¢ {f['audio']} â†” {f['transcript']}")
    
    print(f"\nðŸŽ¤ Minimal Pairs (ISLE): {len(isle_files)} files")
    print("   - Short utterances (~1-3 seconds)")
    print("   - Single-line uppercase transcripts")
    for f in isle_files:
        print(f"   â€¢ {f['audio']} â†” {f['transcript']}")
        print(f"     Content: \"{f['content_preview']}\"")
    
    # MFA-specific recommendations
    print("\n" + "=" * 60)
    print("MFA Preparation Notes:")
    print("=" * 60)
    print("""
âœ“ All files are properly paired - ready for MFA!

âš  Important Considerations:
  1. ISLE files use uppercase transcripts - MFA dictionary must match case
  2. F2BJRLP files have multi-line transcripts - may need preprocessing
  3. Mixed .txt/.TXT extensions detected - ensure case-insensitive matching

Next Steps:
  â†’ Run prepare_mfa_dataset.py to organize data for MFA
  â†’ Download MFA dictionary: english_us_arpa
  â†’ Execute forced alignment
    """)
    
    return len(paired_files) == len(wav_files)

if __name__ == "__main__":
    success = validate_dataset()
    exit(0 if success else 1)
